<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Practically Insignificant</title>
    <link>/</link>
    <description>Recent content on Practically Insignificant</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bounded Bayes: Markov Chain Monte Carlo (MCMC) for Posteriors of Bounded Parameters</title>
      <link>/post/bounded-bayes/</link>
      <pubDate>Thu, 17 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/bounded-bayes/</guid>
      <description>
&lt;link href=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;/rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;script src=&#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;&gt;&lt;/script&gt;
&lt;!--

Time spent:

161220, 10 min
171220, 40 min

--&gt;
&lt;p&gt;This is largely a note to my past-self on how to easily use Markov Chain Monte Carlo (MCMC) methods for Bayesian inference when the parameter you are interested in has bounded support. The most basic MCMC methods involve using additive noise to get new draws, which can cause problems if that kicks you out of the parameter space.&lt;/p&gt;
&lt;p&gt;Suggestions abound to use the transformation trick on a bounded parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt;, and then make draws of the transformed parameter. But I could not easily find a worked example. So here’s that worked example.&lt;/p&gt;
&lt;p&gt;Suppose we want to simulate from the posterior distribution of a parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; with a bounded parameter space. Select an invertible function &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; that maps the bounded parameter space to the real line, i.e.
&lt;span class=&#34;math display&#34;&gt;\[\psi = g(\theta) \text{ where } g : \Theta \to \mathbb{R}.\]&lt;/span&gt;
Then simulate from the posterior density &lt;span class=&#34;math inline&#34;&gt;\(f_{\Psi \mid \mathbf{X}}(\psi \mid \mathbf{x})\)&lt;/span&gt; in terms of the transformed parameter &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;. By the transformation theorem,
&lt;span class=&#34;math display&#34;&gt;\[\psi \mid \mathbf{X} = \mathbf{x} \sim f_{\Psi \mid \mathbf{X}}(\psi \mid \mathbf{x}) = \frac{f_{\Theta \mid \mathbf{X}}(g^{-1}(\psi) \mid \mathbf{x})}{|g&amp;#39;(g^{-1}(\psi))|},\]&lt;/span&gt;
where the posterior &lt;span class=&#34;math inline&#34;&gt;\(f_{\Theta \mid \mathbf{X}}\)&lt;/span&gt; is known, at least up to the likelihood and prior.&lt;/p&gt;
&lt;p&gt;Let’s use this to simulate a success probability for a binomial proportion from the posterior density &lt;span class=&#34;math inline&#34;&gt;\(f_{P \mid X}(p \mid x)\)&lt;/span&gt;. Here, because &lt;span class=&#34;math inline&#34;&gt;\(p \in (0, 1)\)&lt;/span&gt;, it’s natural to use the logit function to map from &lt;span class=&#34;math inline&#34;&gt;\((0, 1)\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\((-\infty, \infty)\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[
\psi = \operatorname{logit}(p) = \log \frac{p}{1-p}
\]&lt;/span&gt;
The transformation theorem then gives the posterior in terms of &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; as:
&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned} 
  f_{\Psi \mid X}(\psi \mid x) &amp;amp;= \frac{f_{P \mid X}(\operatorname{logit}^{-1}(\psi) \mid x)}{|\operatorname{logit}&amp;#39;(\operatorname{logit}^{-1}(\psi))|}  \\
  &amp;amp;= f_{P \mid X}(p \mid x) \times p(1-p)
  \end{aligned}
\]&lt;/span&gt;
where
&lt;span class=&#34;math display&#34;&gt;\[
p = \operatorname{logit}^{-1}(\psi) = \frac{e^{\psi}}{1 + e^{\psi}}.
\]&lt;/span&gt;
Sampling &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; via a random walk and using the Metropolis-Hastings update rule now gives a chain in terms of &lt;span class=&#34;math inline&#34;&gt;\(\psi_{1}, \psi_{2}, \ldots, \psi_{B}\)&lt;/span&gt;, which can be transformed via &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{logit}^{-1}\)&lt;/span&gt; into a chain in terms of &lt;span class=&#34;math inline&#34;&gt;\(p_{1}, p_{2}, \ldots, p_{B}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s use the Jeffreys prior for &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;: &lt;span class=&#34;math inline&#34;&gt;\(P \sim \operatorname{Be}(1/2, 1/2)\)&lt;/span&gt;. In this case, we can easily work out the posterior, but let’s use a &lt;a href=&#34;http://www.stats.org.uk/priors/noninformative/YangBerger1998.pdf&#34;&gt;lookup table&lt;/a&gt; put together by Ruoyong Yang and Jim Berger. The posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt; given we observe &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; successes in &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; trials is &lt;span class=&#34;math inline&#34;&gt;\(P \mid X = x \sim \operatorname{Be}(x + 1/2, n - x + 1/2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We know the posterior in terms of &lt;span class=&#34;math inline&#34;&gt;\(\psi = \operatorname{logit}(p)\)&lt;/span&gt; is
&lt;span class=&#34;math display&#34;&gt;\[f(\psi \mid x) \propto f(x \mid \psi) f(\psi).\]&lt;/span&gt;
Moreover, the posterior in terms of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}  
    f(p \mid x) &amp;amp;\propto f(x \mid p) f(p) \\
    &amp;amp;= \texttt{dbinom(x, n, p)*dbeta(p, 1/2, 1/2)} 
\end{aligned}
\]&lt;/span&gt;
And the posterior in terms of &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt; is just the posterior in terms of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, modified by the multiplicative factor that takes care of the transformation from &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[
f(\psi \mid x) \propto f(p \mid x) p (1-p) \bigg\rvert_{p = \operatorname{logit}^{-1}(\psi)}
\]&lt;/span&gt;
This is the posterior distribution we will make draws from using Metropolis-Hastings, i.e. given that we have &lt;span class=&#34;math inline&#34;&gt;\(\psi_{1}, \psi_{2}, \ldots, \psi_{t-1}\)&lt;/span&gt;, generate a new potential draw &lt;span class=&#34;math inline&#34;&gt;\(\psi_{t} = \psi_{t-1} + \epsilon_{t}\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{t} \sim N(0, \sigma^{2})\)&lt;/span&gt;, and compute
&lt;span class=&#34;math display&#34;&gt;\[ 
A = \min \left\{1, \frac{f(\psi_{t} \mid x)}{f(\psi_{t-1} \mid x)} \right\}.
\]&lt;/span&gt;
We then accept &lt;span class=&#34;math inline&#34;&gt;\(\psi_{t}\)&lt;/span&gt; with probability &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt;, or otherwise repeat the previous draw, i.e. &lt;span class=&#34;math inline&#34;&gt;\(\psi_{t} = \psi_{t-1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s define some functions for the logit and inverse logit functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;logit &amp;lt;- function(p) log(p/(1-p))
invlogit &amp;lt;- function(psi) exp(psi)/(1 + exp(psi))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And to compute the numerator of the posterior distribution of &lt;span class=&#34;math inline&#34;&gt;\(\Psi \mid X = x\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior.numer &amp;lt;- function(psi){
  p = invlogit(psi)
  dbinom(x, n, p)*dbeta(p, 1/2, 1/2)*p*(1-p)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’re ready to simulate from the posterior distribution via Metropolis-Hastings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1) # For reproducibility

n &amp;lt;- 2
x &amp;lt;- 1

B &amp;lt;- 100000

psis &amp;lt;- rep(0, length(B))

for (b in 2:B){
  candidate.psi &amp;lt;- psis[b-1] + rnorm(1, 0, 1)
  
  A &amp;lt;- min(c(1, posterior.numer(candidate.psi)/posterior.numer(psis[b-1])))
  
  if (runif(1) &amp;lt;= A){ # Accept candidate.psi with probability A
    psis[b] &amp;lt;- candidate.psi
  }else{ # Reject candidate.psi and repeat psis[b-1]
    psis[b] &amp;lt;- psis[b-1]
  }
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can view the Markov chains for the posterior distributions in terms of either the &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;s or the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;s:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(2, 1))
plot(psis, type = &amp;#39;l&amp;#39;, xlim = c(1, 1000))
plot(invlogit(psis), type = &amp;#39;l&amp;#39;, xlim = c(1, 1000))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-17-bounded-bayes_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And the posterior distributions in terms of either the &lt;span class=&#34;math inline&#34;&gt;\(\psi\)&lt;/span&gt;s or the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;s:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(1, 2))
hist(psis, breaks = &amp;#39;FD&amp;#39;, main = &amp;#39;&amp;#39;)
hist(invlogit(psis), breaks = &amp;#39;FD&amp;#39;, freq = FALSE, xlim = c(0, 1), main = &amp;#39;&amp;#39;)
curve(dbeta(p, x + 0.5, n - x + 0.5), xname = &amp;#39;p&amp;#39;, add = TRUE, col = &amp;#39;blue&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-17-bounded-bayes_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, the simulated draws match the true posterior, as they must.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How Confident Are We that Masks &#34;Work&#34;? Confidence Functions and the DANMASK-19 Study</title>
      <link>/post/confidence-covid-mask-protection/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/confidence-covid-mask-protection/</guid>
      <description>


&lt;script src=&#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;&gt;&lt;/script&gt;
&lt;!--

Time spent:

061220, 30 min
061220, 38 min

--&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Attention Conservation Notice:&lt;/strong&gt; I use a recent study about COVID-19 as an excuse to demo an R package I am developing. Some other reasons not to read this: (a) I am not an epidemiologist and (b) I do not plan to explain confidence functions enough for the uninitiated to make sense of this post.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Andrew Gelman had an interesting &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2020/12/04/discussion-of-uncertainties-in-the-coronavirus-mask-study-leads-us-to-think-about-some-issues/&#34;&gt;post&lt;/a&gt; recently about the &lt;a href=&#34;https://www.acpjournals.org/doi/10.7326/M20-6817&#34;&gt;DANMASK-19 trial&lt;/a&gt; out of Denmark. This study randomized individuals to recieve a mask recommendation and a supply of 50 surgical masks (or not):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Encouragement to follow social distancing measures for coronavirus disease 2019, plus either no mask recommendation or a recommendation to wear a mask when outside the home among other persons together with a supply of 50 surgical masks and instructions for proper use.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From that study’s results synopsis:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A total of 3030 participants were randomly assigned to the recommendation to wear masks, and 2994 were assigned to control; 4862 completed the study. Infection with SARS-CoV-2 occurred in 42 participants recommended masks (1.8%) and 53 control participants (2.1%). The between-group difference was −0.3 percentage point (95% CI, −1.2 to 0.4 percentage point; P = 0.38) (odds ratio, 0.82 [CI, 0.54 to 1.23]; P = 0.33). Multiple imputation accounting for loss to follow-up yielded similar results. Although the difference observed was not statistically significant, the 95% CIs are compatible with a 46% reduction to a 23% increase in infection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And the synopsis conclusion:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The recommendation to wear surgical masks to supplement other public health measures did not reduce the SARS-CoV-2 infection rate among wearers by more than 50% in a community with modest infection rates, some degree of social distancing, and uncommon general mask use. The data were compatible with lesser degrees of self-protection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I won’t focus on the design of the study, except to make the obvious point: the target of this study is whether the &lt;strong&gt;recommendation to wear and provision of masks&lt;/strong&gt; reduces rates of SARS-CoV-2 infection, &lt;em&gt;not&lt;/em&gt; whether &lt;strong&gt;wearing masks&lt;/strong&gt; reduces rates SARS-CoV-2 infection. Those are two very different questions.&lt;/p&gt;
&lt;p&gt;With that caveat out of the way, let’s look at some of the inferential statistics resulting from this study and how they might be better-reported using &lt;a href=&#34;https://www.mn.uio.no/math/english/research/projects/focustat/the-focustat-blog!/confidence-dummies.html&#34;&gt;confidence functions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We begin with the difference between the reported rates of SARS-CoV-2 infection in the control (&lt;span class=&#34;math inline&#34;&gt;\(p_{C}\)&lt;/span&gt;) and treatment (&lt;span class=&#34;math inline&#34;&gt;\(p_{T}\)&lt;/span&gt;) groups: &lt;span class=&#34;math inline&#34;&gt;\(\delta = p_{C} - p_{T}\)&lt;/span&gt;. The sample estimates of these rates are the obvious things: the proportion of individuals in the study who develop symptoms of COVID-19,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# p[1] = rate of SARS-CoV-2 in control arm
# p[2] = rate of SARS-CoV-2 in intervention arm

x &amp;lt;- c(53, 42)
n &amp;lt;- c(2470, 2392)

(p&amp;lt;-x/n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02145749 0.01755853&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the sample estimate for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; is also the obvious estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p[1] - p[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.003898961&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The authors report a two-sided &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for the null hypothesis of no difference in rates between the two arms of the study, i.e. hte &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for the test
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} H_{0} &amp;amp;: p_{C} - p_{T} = \delta_{0} = 0 \\ H_{1} &amp;amp;: p_{C} - p_{T} \neq \delta_{0} = 0 \end{aligned}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s construct confidence functions for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;, rather than just compute the particular &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for the particular null value.&lt;/p&gt;
&lt;p&gt;We load in the &lt;code&gt;clp&lt;/code&gt; package (which you can find a beta version of &lt;a href=&#34;https://github.com/ddarmon/clp&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(clp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then use the &lt;code&gt;prop.conf()&lt;/code&gt; function form confidence functions for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.diff.props &amp;lt;- clp::prop.conf(x = x, n = n, plot = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, from the confidence quantile function &lt;code&gt;qconf()&lt;/code&gt;, we can recover the point estimate for the difference in risks as a percentage as the median of the confidence distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.diff.props$qconf(0.5)*100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3899442&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which matches (up to some numerical fuzz) the direct point estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(p[1] - p[2])*100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3898961&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also recover the 95% confidence interval from &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; by taking the 2.5th and 97.5th percentiles of the confidence distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.diff.props$qconf(c(0.025, 0.975))*100&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.3880645  1.2092257&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we get the two-sided &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for the null hypothesis that &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt; using &lt;code&gt;pcurve()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.diff.props$pcurve(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3261612&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Comparing to the study’s inferential statistics:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The between-group difference was −0.3 percentage point (95% CI, −1.2 to 0.4 percentage point; P = 0.38) (odds ratio, 0.82 [CI, 0.54 to 1.23]; P = 0.33).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;we get more-or-less the same results, up to their choice of sign. I attribute the small differences between their values and mine to them using a Wald statistic, rather than a score statistic, to construct their intervals and compute their hypothesis tests. I used the (generally better behaved, especially for small risks) &lt;a href=&#34;https://www.researchgate.net/publication/233397715_Confidence_intervals_for_the_ratio_and_difference_of_two_binomial_proportions&#34;&gt;score statistic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But why stop with a 95% confidence interval? We can show all possible confidence intervals for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; via the confidence curve by calling &lt;code&gt;plot.cconf()&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot.cconf(conf.diff.props,
           xlab = &amp;#39;p[1] - p[2]&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yes, &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt; (no difference) is contained in the 95% confidence interval, so we would fail to reject &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt; at a 5% significance level. But the weight of the evidence is for the mask-PSA intervention being &lt;strong&gt;more effective&lt;/strong&gt; than no-intervention. We can make this clearer by plotting the confidence density for &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot.dconf(conf.diff.props,
           xlab = &amp;#39;p[1] - p[2]&amp;#39;)

x.shade &amp;lt;- seq(0, 0.03, length.out = 100)
polygon(x = c(0, 
              x.shade,
              rev(x.shade),
              0),
        y = c(0, 
              rep(0, length(x.shade)),
              conf.diff.props$dconf(rev(x.shade)),
              0),
        col = rgb(0, 1, 0, alpha = 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The green shaded area is the fiducial probability associated with &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; being positive (positive impact of the mask-PSA), which we can compute using the complementary confidence distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1-conf.diff.props$pconf(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8369194&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;83.7% of the evidence is in favor of the mask-PSA having &lt;strong&gt;some&lt;/strong&gt; positive impact compared to no-PSA. This corresponds to the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;- value for the left-sided test
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} H_{0} &amp;amp;: \delta \geq 0 \\ H_{1} &amp;amp;: \delta &amp;lt; 0 \end{aligned}\]&lt;/span&gt;
We get the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for the right-sided test
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} H_{0} &amp;amp;: \delta \leq 0 \\ H_{1} &amp;amp;: \delta &amp;gt; 0 \end{aligned}\]&lt;/span&gt;
by direct use of the confidence distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.diff.props$pconf(0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1630806&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and thus have weaker evidence for the mask-PSA being &lt;strong&gt;less&lt;/strong&gt; effective than the no-PSA intervention.&lt;/p&gt;
&lt;p&gt;The main takeaway from this study, of course, is that we just don’t know for sure whether the mask-PSA worked or not. The weight of evidence is in favor of the mask-PSA working, but we would need a new study, with more participants, to get a better idea. Though, since we can never step in the same river twice, other things are clearly different in Denmark now compared to April and May of 2020. This reminds us that there is no “&lt;strong&gt;the&lt;/strong&gt; effect of a mask-PSA,” as the effectiveness of that PSA will vary depending on all of the contingencies currently in play.&lt;/p&gt;
&lt;p&gt;We can repeat the same analysis with the relative risk and odds ratio, other common parameters when assessing changes in risk. The relative risk (or risk ratio) is defined as
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} \rho &amp;amp;= \frac{\text{Risk in Treatment}}{\text{Risk in Control}} \\ &amp;amp;= \frac{p_{T}}{p_{C}}   \end{aligned}\]&lt;/span&gt;
and we can compute the confidence functions using &lt;code&gt;clp&lt;/code&gt;’s &lt;code&gt;riskratio.conf()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.rel.risk &amp;lt;- clp::riskratio.conf(x, n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-13-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;and get out the median of the confidence distribution&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.rel.risk$qconf(0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8182709&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which matches the obvious point estimate of the relative risk from the sample:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p[2]/p[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8182937&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We compute a 95% confidence distribution for &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; using the confidence quantile:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.rel.risk$qconf(c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5493596 1.2186575&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So the data are consistent with anywhere from a 45% reduction in risk for the treatment group to a 22% increase in risk for the treatment group. This matches the portion of their results synopsis:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Although the difference observed was not statistically significant, the 95% CIs are compatible with a 46% reduction to a 23% increase in infection.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Though, again, they’re presumably using a Wald statistic rather than a score statistic to compute their confidence interval.&lt;/p&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for a two-sided test of &lt;span class=&#34;math inline&#34;&gt;\(\rho = 1\)&lt;/span&gt; (if we must have it), is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.rel.risk$pcurve(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3261612&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where we use &lt;span class=&#34;math inline&#34;&gt;\(\rho = 1\)&lt;/span&gt; since a risk ratio of 1 indicates no difference in risk between the two groups. This exactly matches the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for &lt;span class=&#34;math inline&#34;&gt;\(\delta = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Finally, all the same analyses, but using the odds ratio
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} \omega &amp;amp;= \frac{\text{Odds(Infection; Treatment)}}{\text{Odds(Infection; Control)}} \\ &amp;amp;= \frac{p_{T}/(1 - p_{T})}{p_{C}/(1-p_{C})}   \end{aligned}\]&lt;/span&gt;
I’ll leave out the color commentary this time:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.odds.ratio &amp;lt;- clp::oddsratio.conf(x, n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;img src=&#34;/post/2020-12-06-confidence-covid-mask-protection_files/figure-html/unnamed-chunk-18-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.odds.ratio$qconf(0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8150468&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;odds.control   &amp;lt;- p[1]/(1-p[1])
odds.treatment &amp;lt;- p[2]/(1-p[2])

odds.treatment/odds.control&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8150462&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.odds.ratio$qconf(c(0.025, 0.975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.541522 1.226716&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf.odds.ratio$pcurve(1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3269062&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Quantum Statistics: Exact Tests with Discrete Test Statistics</title>
      <link>/post/the-land-of-lost-significance-exact-tests-with-discrete-test-statistics/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/the-land-of-lost-significance-exact-tests-with-discrete-test-statistics/</guid>
      <description>


&lt;script src=&#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;&gt;&lt;/script&gt;
&lt;!--

Time spent:

280620, 22 minutes
280620, 34 minutes
280620, 30 minutes

--&gt;
&lt;p&gt;For those who ended up here looking for information about &lt;a href=&#34;https://en.wikipedia.org/wiki/Quantum_statistical_mechanics&#34;&gt;quantum statistical mechanics&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Particle_statistics&#34;&gt;particle statistics&lt;/a&gt;: apologies! But sometimes I feel like physicists took all the exciting names, so I’m stealing the term quanta as it relates to an observable that can take on only discrete (not continuous values). That has interesting consequences for inferential procedures based on such discrete (“quantum”) statistics, as we will see in this post.&lt;/p&gt;
&lt;p&gt;Consider performing a hypothesis test for a binomial proportion &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. For example, imagine that you want to come to a tentative conclusion about the bias of a coin after flipping it 10 times.&lt;/p&gt;
&lt;p&gt;Let &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; be the number of times that the coin comes up heads out of 10 flips. Then &lt;span class=&#34;math inline&#34;&gt;\(X \sim \mathrm{Binom}(n = 10, p)\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is the bias of the coin to come up heads. We really want to show that the bias of the coin is smaller than a certain value &lt;span class=&#34;math inline&#34;&gt;\(p_{0}\)&lt;/span&gt;, but we do not want to reject that the bias is greater than or equal to &lt;span class=&#34;math inline&#34;&gt;\(p_{0}\)&lt;/span&gt; too easily. So we set up the left-sided hypothesis test:
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} H_{0} &amp;amp;: p \geq p_{0} \\ H_{1} &amp;amp;: p &amp;lt; p_{0} \end{aligned}.\]&lt;/span&gt;
We will take &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}}\)&lt;/span&gt;, the number of observed heads out of our 10 flips, as our test statistic: the smaller the number of heads, the more evidence against the null hypothesis. We are too lazy to set up a rejection region, so we will resort to using a &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value instead. Recalling that the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is the probability of a test statistic as extreme or more extreme than the observed test statistic when the null hypothesis is true, we find that the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} P(x_{\mathrm{obs}}) &amp;amp;= \sup_{p \geq p_{0}} P_{p}(X \leq x_{\mathrm{obs}}) \\ &amp;amp;= P_{p_{0}}(X \leq x_{\mathrm{obs}}) \end{aligned}\]&lt;/span&gt;
Now to perform a classical hypothesis test, we use the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value as usual. We set up a significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, and reject the null hypothesis whenever our &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;If we were dealing with a continuous test statistic, the analysis we did would be done. The &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value would be less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; a proportion &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; of the time when &lt;span class=&#34;math inline&#34;&gt;\(p = p_{0}\)&lt;/span&gt;, and even more often when &lt;span class=&#34;math inline&#34;&gt;\(p \geq p_{0}\)&lt;/span&gt;, so our worst Type I Error Rate would be &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;But something is different with discrete test statistics. Let’s create a plot of the possible &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values as a function of both the observed test statistic &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}}\)&lt;/span&gt; (which is colored from blue when &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} = 0\)&lt;/span&gt; to red when &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} = n\)&lt;/span&gt;) and the null value &lt;span class=&#34;math inline&#34;&gt;\(p_{0}\)&lt;/span&gt; we want to test. We’ll create a function so we can eventually change &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; to values other than 10:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p.value.plot &amp;lt;- function(n, alpha = 0.05, p0 = 1/2){
  xs &amp;lt;- 0:n

  cols &amp;lt;- colorspace::diverge_hcl(length(xs))
  
  plot(0, 0, cex = 0, xlim = c(0, 1), ylim = c(0, 1),
       xlab = expression(italic(p[0])),
       ylab = expression(italic(P)[italic(p)[0]](italic(X) &amp;lt;= italic(x)[obs])))
  for (x.ind in 1:length(xs)){
    x &amp;lt;- xs[x.ind]
    curve(pbinom(x, n, p), 
          xname = &amp;#39;p&amp;#39;, add = TRUE, col = cols[x.ind],
          n = 2001)
  }
  abline(h = alpha, v = p0, lty = 3)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running this, we get 11 curves, since &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}}\)&lt;/span&gt; can range from 0 to 10:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 10
p.value.plot(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The vertical line gives us a slice through the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values when we want to test that &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; 1/2\)&lt;/span&gt;. The horizontal line shows a desired significance level of &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt; (the favorite number of significance fetishists). And we notice something a bit shocking: if we reject when our &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;, we won’t reject precisely 5% of the time under the worst-case null hypothesis. Instead, we’ll reject something closer to 1% of the time: the size of our test is actually smaller than what we set out to have! The actual size of our test is the largest &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value that is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, which we see is the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value corresponding to &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} = 1\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbinom(1, n, 1/2) # A wee bit too big&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.01074219&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we took the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value for &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} = 2\)&lt;/span&gt;, that would be just a bit too big:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbinom(2, n, 1/2) # A wee bit too small&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0546875&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The actual size of our test is therefore &lt;span class=&#34;math inline&#34;&gt;\(\approx 0.011\)&lt;/span&gt;, Thus, we have “lost” an amount &lt;span class=&#34;math inline&#34;&gt;\(0.05 - 0.011 = 0.039\)&lt;/span&gt; of the desired significance!&lt;/p&gt;
&lt;p&gt;Moreover, we see something else: sometimes &lt;strong&gt;none&lt;/strong&gt; of the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values will be less than our significance level! For example, if we wanted to take our null &lt;span class=&#34;math inline&#34;&gt;\(p_{0}\)&lt;/span&gt; to be 0.2:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p.value.plot(n, p0 = 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;we see that none of the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values are less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;. Thus, we would never reject the null hypothesis, and our Type I Error Rate would, by definition, be 0%: we’ll never reject the null hypothesis when it is true because we’ll never reject the null hypothesis!&lt;/p&gt;
&lt;p&gt;The problem here is that, because the test statistic is discrete, and thus can take on only discrete values, the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value, which is just a particular function of the test statistic, is also discrete. Quantum statistics, as promised! The problem begins to go away as the sample size increases (in this case, as we flip more and more coins). In the limit, in fact, we know the problem must completely go away, since a binomial random variable will converge, by the &lt;a href=&#34;https://en.wikipedia.org/wiki/Central_limit_theorem&#34;&gt;Central Limit Theorem&lt;/a&gt;, on a &lt;a href=&#34;https://en.wikipedia.org/wiki/Normal_distribution&#34;&gt;Gaussian random variable&lt;/a&gt;. We can see that by creating a new plot where we consider flipping 100, rather than just 10, coins:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 100
p.value.plot(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values are beginning to fill up the continuum from 0 to 1, especially so near where &lt;span class=&#34;math inline&#34;&gt;\(p_{0} = 1/2\)&lt;/span&gt;. In this case, we can find the actual size of our test when we use &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt; in the same way: find the largest &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value that is still less than or equal to 0.05:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;xs &amp;lt;- 0:n
Ps &amp;lt;- pbinom(xs, n, 1/2)

x.star &amp;lt;- tail(xs[which(Ps &amp;lt;= 0.05)], 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And again, this gives us a &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value that is a bit too small:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbinom(x.star, n, 1/2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04431304&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but the next largest &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is a bit too big:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbinom(x.star+1, n, 1/2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06660531&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In fact, we can see how the actual size of the test using &lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt; as our cutoff varies as we increase &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;find.size = function(n, alpha = 0.05, p0 = 1/2){
  xs &amp;lt;- 0:n
  Ps &amp;lt;- pbinom(xs, n, p0)
  
  tail(Ps[Ps &amp;lt;= alpha], 1)
}

find.size &amp;lt;- Vectorize(find.size, vectorize.args = &amp;#39;n&amp;#39;)

ns &amp;lt;- 1:200

plot(ns, find.size(ns), ylim = c(0, 0.05), type = &amp;#39;b&amp;#39;, pch = 16, cex = 0.5,
     xlab = expression(italic(n)), ylab = expression(Size(italic(n))))
abline(h = 0.05, lty = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that, by construction, the actual size is always less than or equal to 0.05, and it gets closer, but in a sawtooth way, to the desired significance level. If we take &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; to be quite large, we see:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ns &amp;lt;- 1:2000

plot(ns, find.size(ns), ylim = c(0, 0.05), type = &amp;#39;b&amp;#39;, pch = 16, cex = 0.5,
     xlab = expression(italic(n)), ylab = expression(Size(italic(n))))
abline(h = 0.05, lty = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-the-land-of-lost-significance-exact-tests-with-discrete-test-statistics_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;so the size, at least for certain values of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, only &lt;strong&gt;very slowly&lt;/strong&gt; approaches the desired significance level.&lt;/p&gt;
&lt;p&gt;There’s almost certainly some interesting mathematics in the limiting behavior of the size of this test, and that mathematics has almost certainly been explored! But we will leave that for now. In the next two posts, we will discuss methods for handling the conservativeness of tests that rely on discrete test statistics: randomized rejection and mid &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Salvaging Lost Significance via Randomization: Randomized \(P\)-values for Discrete Test Statistics</title>
      <link>/post/salvaging-lost-significance-via-randomization-randomized-p-values-for-discrete-test-statistics/</link>
      <pubDate>Sun, 28 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/post/salvaging-lost-significance-via-randomization-randomized-p-values-for-discrete-test-statistics/</guid>
      <description>


&lt;script src=&#39;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#39;&gt;&lt;/script&gt;
&lt;!-- 

280620, 57 min

--&gt;
&lt;p&gt;Last time, we saw that when performing a hypothesis test with a discrete test statistic, we will typically lose size unless we happen to be very lucky and have the significance level &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; exactly match one of our possible &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values. In this post, I will introduce a randomized hypothesis test that will regain the size we lost. Unlike a lot of randomization in statistics, the randomization here comes at the end: we randomize the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value in order to recover the size. In many cases (ideally!), experimentalists use randomization at the beginning of their experiment, by (ideally) randomly sampling from a population and then randomly assigning units to a treatment. But the extra step of randomizing at the end, when they’re eagerly awaiting to find out whether they’ve been so-blessed with significance stars, they may balk at randomization, even though it makes their test more powerful. I will allow them their balking (I might, too, if my career depended on accumulating many, many stickers), and in the next post I will discuss a method that gets rid of the random element of randomized &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-values while still guarding against the conservativeness of the test.&lt;/p&gt;
&lt;p&gt;For this exercise, let’s consider a right-sided test. (Why? Because I had already made all the figures and schematics for a right-sided test before writing the last post, and don’t want to remake them for the left-sided test!) Again, consider the case of performing a hypothesis test
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} H_{0} &amp;amp;: p \leq p_{0} \\ H_{1} &amp;amp;: p &amp;gt; p_{0}\end{aligned}\]&lt;/span&gt;
for a binomial proportion &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; using a binomial random variable &lt;span class=&#34;math inline&#34;&gt;\(X \sim \mathrm{Binom}(n, p)\)&lt;/span&gt;. The classical right-sided &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is then
&lt;span class=&#34;math display&#34;&gt;\[P = P_{p_{0}}(X \geq x_{\mathrm{obs}}).\]&lt;/span&gt;
We know that this will, generally, be slightly too small at a boundary value of &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}}\)&lt;/span&gt;: the difference between the largest &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt; will be non-zero unless we happen to have a “nice” sample size where that &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is close to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. But we also know that &lt;span class=&#34;math inline&#34;&gt;\(P_{p_{0}}(X &amp;gt; x_{\mathrm{obs}})\)&lt;/span&gt; will be slightly too big, since this is the first &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value that is stricly greater than &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. The idea of a randomized &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is to add a little fuzz to the classical right-sided &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value that will place us somewhere between &lt;span class=&#34;math inline&#34;&gt;\(P_{p_{0}}(X \geq x_{\mathrm{obs}})\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(P_{p_{0}}(X &amp;gt; x_{\mathrm{obs}})\)&lt;/span&gt;. That is, the randomized &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is
&lt;span class=&#34;math display&#34;&gt;\[P_{\mathrm{rand}} = P_{p_{0}}(X &amp;gt; x_{\mathrm{obs}}) + U \times P_{p_{0}}(X = x_{\mathrm{obs}})\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; is a uniform random variable on &lt;span class=&#34;math inline&#34;&gt;\((0, 1)\)&lt;/span&gt; that is independent of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Why does this work? Consider the sketch below, which shows the survival function &lt;span class=&#34;math inline&#34;&gt;\(S(k) = P(X &amp;gt; k)\)&lt;/span&gt; and its left-continuous analog &lt;span class=&#34;math inline&#34;&gt;\(S(k^{-}) = P(X \geq k)\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 10
p &amp;lt;- 0.5

alpha = 0.4

ns &amp;lt;- 0:n

Ss &amp;lt;- pbinom(ns, n, p, lower.tail = FALSE)

par(mar=c(5,5,2,1), cex.lab = 2, cex.axis = 2)
plot(ns, Ss, type = &amp;#39;s&amp;#39;,
     xlab = expression(italic(k)), ylab = &amp;#39;Probability&amp;#39;)

Ss.p1 &amp;lt;- Ss + dbinom(ns, n, p)
points(ns, Ss, col = &amp;#39;blue&amp;#39;, pch = 16)
lines(ns, Ss.p1, col = &amp;#39;red&amp;#39;, type = &amp;#39;p&amp;#39;, pch = 16)

abline(h = alpha, lty = 3, col = &amp;#39;purple&amp;#39;)
abline(h = c(0, 1), lty = 3)
abline(v = c(0, n), lty = 3)

legend(&amp;#39;topright&amp;#39;, legend = c(expression(P(italic(X) &amp;gt;= italic(k))),
                              expression(P(italic(X) &amp;gt; italic(k)))),
       col = c(&amp;#39;red&amp;#39;, &amp;#39;blue&amp;#39;), pch = 1, cex = 1.2)

arrows(0.5, 0, 0.5, alpha, code = 3, col = &amp;#39;purple&amp;#39;, lwd = 2, length = 0.15)
text(x = 0.5, y = alpha+0.05, labels = expression(alpha), col = &amp;#39;purple&amp;#39;, cex = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-06-28-salvaging-lost-significance-via-randomization-randomized-p-values-for-discrete-test-statistics_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
Here, &lt;span class=&#34;math inline&#34;&gt;\(S(k^{-})\)&lt;/span&gt; is the classical &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value, &lt;span class=&#34;math inline&#34;&gt;\(S(k)\)&lt;/span&gt; is the “too large” &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value, and the randomized &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value interpolates (randomly) between the classical &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value and the too small &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value:
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} P_{\mathrm{rand}} &amp;amp;= P_{p_{0}}(X &amp;gt; x_{\mathrm{obs}}) + U \times P_{p_{0}}(X = x_{\mathrm{obs}}) \\ &amp;amp;= (1 - U) \times P_{p_{0}}(X &amp;gt; x_{\mathrm{obs}}) + U \times P_{p_{0}}(X \geq x_{\mathrm{obs}}) \\ &amp;amp;= (1-U) S(x_{\mathrm{obs}}) + U S(x_{\mathrm{obs}}^{-}). \end{aligned}\]&lt;/span&gt;
The only place where the randomization has any effect occurs where the interpolating line crosses &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;; otherwise, anywhere we lie on the interpolating line we come to the same decision. Let &lt;span class=&#34;math inline&#34;&gt;\(k^{*}\)&lt;/span&gt; be the first &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; such that &lt;span class=&#34;math inline&#34;&gt;\(P(X &amp;gt; k) \leq \alpha\)&lt;/span&gt;. For &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} &amp;lt; k^{*}\)&lt;/span&gt;, we fail to reject &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt; and for &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} &amp;gt; k^{*}\)&lt;/span&gt;, we reject &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt;. When &lt;span class=&#34;math inline&#34;&gt;\(x_{\mathrm{obs}} = k^{*}\)&lt;/span&gt;, we use the randomization device. We should only reject when the randomized &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, and hence when we fall in the portion of the interpolating line that is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. Rotating the figure above 90º counterclockwise, we have
&lt;p&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/ddarmon/master/master/images/randomized-p-value-schematic.png&#34; width=&#34;600&#34;&gt;
&lt;p&gt;
&lt;p&gt;and we should only reject when the &lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;-value falls at or below &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;. Because &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; is uniform, the probability that this occurs is
&lt;span class=&#34;math display&#34;&gt;\[P\left(U \leq \frac{\alpha - S(k^{*})}{p(k^{*})} \right) = \frac{\alpha - S(k^{*})}{p(k^{*})}.\]&lt;/span&gt;
So on the boundary of the rejection region, we reject &lt;span class=&#34;math inline&#34;&gt;\(H_{0}\)&lt;/span&gt; with probability &lt;span class=&#34;math inline&#34;&gt;\(\frac{\alpha - S(k^{*})}{p(k^{*})}\)&lt;/span&gt;. Let &lt;span class=&#34;math inline&#34;&gt;\(\phi(X)\)&lt;/span&gt; be our rejection rule, i.e. the function that is 1 when we reject the null hypothesis and 0 otherwise. Then &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt; is a random function with the conditional distribution
&lt;span class=&#34;math display&#34;&gt;\[P(\phi(X) = 1 \mid X = k) = \begin{cases} 0 &amp;amp;: k &amp;lt; k^{*} \\ \frac{\alpha - S(k^{*})}{p(k^{*})} &amp;amp;: k = k^{*} \\ 1 &amp;amp;: k &amp;gt; k^{*} \end{cases}.\]&lt;/span&gt;
Given this definition, it’s straightforward to prove that the probability that we reject the null hypothesis, that is, that &lt;span class=&#34;math inline&#34;&gt;\(\phi(X) = 1\)&lt;/span&gt;, is in fact &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;:
&lt;span class=&#34;math display&#34;&gt;\[\begin{aligned} P(\phi(X) = 1) &amp;amp;= \sum_{k} P(\phi(X) = 1 \mid X = k) P(X = k) \\ &amp;amp;= \sum_{\{k : k &amp;lt; k^{*}\}} 0 \cdot p(k) + \frac{\alpha - S(k^{*})}{p(k^{*})} p(k^{*}) + \sum_{\{k : k &amp;gt; k^{*}\}} 1 \cdot p(k) \\ &amp;amp;= \alpha - S(k^{*}) + S(k^{*}) \\ &amp;amp;= \alpha,\end{aligned}\]&lt;/span&gt;
just as we wanted.&lt;/p&gt;
&lt;p&gt;So a little uncertainty at the end buys us back our size, and we attain the desired significance level.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>