<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Practically Insignificant  | How to Burn Money and Computing Power for a Simple Median</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.120.4">
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/dist/css/app.d98f2eb6bcd1eaedb7edf166bd16af26.css" rel="stylesheet">
    

    

    
      
    

    
    
    <meta property="og:title" content="How to Burn Money and Computing Power for a Simple Median" />
<meta property="og:description" content="NOTE: This is a parody post. It was generated by providing my code to GPT-4 with the prompt:
Turn this into a blog post with the title &quot;World&#39;s Most Expensive Way to Compute a Mean or Median&quot; and then asking GPT-4 to make its initial post even more entertaining and sarcastic.
Introduction Today, we dive into the comedic world of absurdly over-engineered solutions for simple problems. Our target? Calculating a mean or median using R and TensorFlow in what might be the most hilariously unnecessary method ever conceived." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2023-12-02-how-to-burn-money-and-computing-power-for-a-simple-median/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2023-12-02T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-12-02T00:00:00+00:00" />

<meta itemprop="name" content="How to Burn Money and Computing Power for a Simple Median">
<meta itemprop="description" content="NOTE: This is a parody post. It was generated by providing my code to GPT-4 with the prompt:
Turn this into a blog post with the title &quot;World&#39;s Most Expensive Way to Compute a Mean or Median&quot; and then asking GPT-4 to make its initial post even more entertaining and sarcastic.
Introduction Today, we dive into the comedic world of absurdly over-engineered solutions for simple problems. Our target? Calculating a mean or median using R and TensorFlow in what might be the most hilariously unnecessary method ever conceived."><meta itemprop="datePublished" content="2023-12-02T00:00:00+00:00" />
<meta itemprop="dateModified" content="2023-12-02T00:00:00+00:00" />
<meta itemprop="wordCount" content="548">
<meta itemprop="keywords" content="humorous,R," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="How to Burn Money and Computing Power for a Simple Median"/>
<meta name="twitter:description" content="NOTE: This is a parody post. It was generated by providing my code to GPT-4 with the prompt:
Turn this into a blog post with the title &quot;World&#39;s Most Expensive Way to Compute a Mean or Median&quot; and then asking GPT-4 to make its initial post even more entertaining and sarcastic.
Introduction Today, we dive into the comedic world of absurdly over-engineered solutions for simple problems. Our target? Calculating a mean or median using R and TensorFlow in what might be the most hilariously unnecessary method ever conceived."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      Practically Insignificant
    </a>
    <div class="flex-l items-center">
      

      
      












    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">How to Burn Money and Computing Power for a Simple Median</h1>
      
      <p class="tracked">
         By <strong>GPT-4, with Assistance from David Darmon</strong>
      </p>
      
      
      <time class="f6 mv4 dib tracked" datetime="2023-12-02T00:00:00Z">December 2, 2023</time>
      
      
    </header>

    <section class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">


<p><strong>NOTE:</strong> This is a parody post. It was generated by providing my code to GPT-4 with the prompt:</p>
<pre><code>Turn this into a blog post with the title &quot;World&#39;s Most Expensive Way to Compute a Mean or Median&quot;</code></pre>
<p>and then asking GPT-4 to make its initial post even more entertaining and sarcastic.</p>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>Today, we dive into the comedic world of absurdly over-engineered solutions for simple problems. Our target? Calculating a mean or median using R and TensorFlow in what might be the most hilariously unnecessary method ever conceived.</p>
</div>
<div id="overkill-environment-setup" class="section level3">
<h3>Overkill Environment Setup</h3>
<p>First things first: setting up our R environment. Sure, we could go easy with <code>dplyr</code> and <code>ggplot2</code>, but where’s the fun in that? Instead, let’s summon the computational titans - <code>keras</code> and <code>tensorflow</code>. Because obviously, when you think of finding a median, you think of deep learning, right?</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(keras)
library(tensorflow)
reticulate::use_virtualenv(&quot;r-tensorflow&quot;)</code></pre>
</div>
<div id="creating-a-monster-dataset" class="section level3">
<h3>Creating a Monster Dataset</h3>
<p>We’re cooking up a dataset <code>y</code> with 10,000 log-normally distributed random numbers. Normally, a simple task, but not today, folks. Today, we go big.</p>
<pre class="r"><code>n &lt;- 10000
y &lt;- rlnorm(n)
x &lt;- as.matrix(rep(1, n))</code></pre>
</div>
<div id="frankensteins-neural-network" class="section level3">
<h3>Frankenstein’s Neural Network</h3>
<p>Now for the pièce de résistance: a neural network model using Keras, which is like using a sledgehammer to crack a nut:</p>
<pre class="r"><code>u_per_h &lt;- 5
H &lt;- 10
activation &lt;- &quot;tanh&quot;

model &lt;- keras_model_sequential(input_shape = c(1L))

for (h in seq_len(H)) {
  model %&gt;%
    layer_dense(units = u_per_h, activation = activation)
}

model %&gt;%
  layer_dense(units = 1, activation = NULL)</code></pre>
<pre class="r"><code>model</code></pre>
<pre><code>## Model: &quot;sequential&quot;
## ________________________________________________________________________________
##  Layer (type)                       Output Shape                    Param #     
## ================================================================================
##  dense (Dense)                      (None, 5)                       10          
##  dense_1 (Dense)                    (None, 5)                       30          
##  dense_2 (Dense)                    (None, 5)                       30          
##  dense_3 (Dense)                    (None, 5)                       30          
##  dense_4 (Dense)                    (None, 5)                       30          
##  dense_5 (Dense)                    (None, 5)                       30          
##  dense_6 (Dense)                    (None, 5)                       30          
##  dense_7 (Dense)                    (None, 5)                       30          
##  dense_8 (Dense)                    (None, 5)                       30          
##  dense_9 (Dense)                    (None, 5)                       30          
##  dense_10 (Dense)                   (None, 1)                       6           
## ================================================================================
## Total params: 286 (1.12 KB)
## Trainable params: 286 (1.12 KB)
## Non-trainable params: 0 (0.00 Byte)
## ________________________________________________________________________________</code></pre>
<p>286 parameters to memorize 1 number!</p>
</div>
<div id="training-because-we-can" class="section level3">
<h3>Training: Because We Can</h3>
<p>Let’s train this beast. Our loss function? Mean Absolute Error (MAE). Our optimizer? Stochastic Gradient Descent, because why make it easy?</p>
<pre class="r"><code>loss &lt;- &quot;mae&quot;

model %&gt;%
  compile(
    loss = loss,
    optimizer = optimizer_sgd(learning_rate = 0.03)
  )</code></pre>
<p>Training involves a batch size equal to the length of <code>x</code>, 200 epochs, a 20% validation split, and early stopping to pretend we care about efficiency.</p>
<pre class="r"><code>history &lt;- model %&gt;%
  fit(
    x, y,
    batch_size = nrow(x),
    epochs = 200,
    validation_split = 0.2,
    callbacks = callback_early_stopping(patience = 10, restore_best_weights = TRUE)
  )</code></pre>
<pre class="r"><code>plot(history, smooth = FALSE) +
  theme_bw() +
  theme(text = element_text(size = 20))</code></pre>
<p><img src="/post/2023-12-02-how-to-burn-money-and-computing-power-for-a-simple-median_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="the-grand-reveal" class="section level3">
<h3>The Grand Reveal</h3>
<p>At last, let’s compare the good old-fashioned mean and median with our neural network’s predictions:</p>
<pre class="r"><code>loss</code></pre>
<pre><code>## [1] &quot;mae&quot;</code></pre>
<pre class="r"><code>mean(y)</code></pre>
<pre><code>## [1] 1.656555</code></pre>
<pre class="r"><code>median(y)</code></pre>
<pre><code>## [1] 1.011264</code></pre>
<pre class="r"><code>model(x) %&gt;% head(1)</code></pre>
<pre><code>## tf.Tensor([[1.0070788]], shape=(1, 1), dtype=float32)</code></pre>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>Our journey through the world of computational overkill serves as a hilarious, yet poignant, reminder: sometimes, the simplest tools are the best. This laughably complex method for computing a mean or median underscores the value of choosing the right tool for the task at hand in data analysis. Remember, folks, sometimes less is more!</p>
</div>
<ul class="pa0">
  
   <li class="list">
     <a href="/tags/humorous" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">humorous</a>
   </li>
  
   <li class="list">
     <a href="/tags/r" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">R</a>
   </li>
  
</ul>
<div class="mt6">
      
      
      </div>
    </section>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="/post/2023-12-02-estimating-the-unconditional-median-with-deep-learning-a-practical-approach-using-r-and-keras/">Estimating the Unconditional Median with Deep Learning: A Practical Approach Using R and Keras</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="/" >
    &copy; 2023 Practically Insignificant
  </a>
    <div>











</div>
  </div>
</footer>

    

  <script src="/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
